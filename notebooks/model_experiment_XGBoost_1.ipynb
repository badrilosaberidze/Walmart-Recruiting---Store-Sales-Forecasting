{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6rVobOKlLuE9+Dtk3nMUt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Env Setup\n"],"metadata":{"id":"M3PxgaKXmAyZ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mxf87fIClvqC","executionInfo":{"status":"ok","timestamp":1751987523714,"user_tz":-240,"elapsed":37915,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"f3f98418-6d03-4a29-c4f4-e2d5b2a5fcc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","with open('/content/drive/MyDrive/MLFinal/git_token.env', 'r') as f:\n","    token = f.read().strip()\n","\n","username = \"badrilosaberidze\"\n","\n","%cd /content/drive/MyDrive/MLFinal/walmart-sales-forecasting\n","!git remote set-url origin https://{username}:{token}@github.com/{username}/Walmart-Recruiting---Store-Sales-Forecasting.git\n","!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Pp53putmDBo","executionInfo":{"status":"ok","timestamp":1751987542374,"user_tz":-240,"elapsed":8356,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"53d96f4c-1b49-4fb7-d903-38fae015aed1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MLFinal/walmart-sales-forecasting\n","Already up to date.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.preprocessing import LabelEncoder\n","import wandb\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"6BLZzw4imDfY","executionInfo":{"status":"ok","timestamp":1751987606324,"user_tz":-240,"elapsed":6409,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Wmae Calculation"],"metadata":{"id":"7vvquvNTsBFt"}},{"cell_type":"code","source":["def calculate_wmae(y_true, y_pred, is_holiday):\n","    \"\"\"\n","    Calculate Weighted Mean Absolute Error (WMAE)\n","    Holiday weeks have 5x weight\n","    \"\"\"\n","    weights = np.where(is_holiday, 5.0, 1.0)\n","    weighted_errors = weights * np.abs(y_true - y_pred)\n","    wmae = np.sum(weighted_errors) / np.sum(weights)\n","    return wmae"],"metadata":{"id":"fIbB0vQrsCff","executionInfo":{"status":"ok","timestamp":1751989104162,"user_tz":-240,"elapsed":44,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["#XGBoost Model"],"metadata":{"id":"d0nA8KOLmWEZ"}},{"cell_type":"code","source":["class WalmartXGBoostBaseline:\n","    \"\"\"\n","    XGBoost baseline for Walmart sales forecasting\n","\n","    Key Insights from ARIMA work to apply:\n","    1. Department-level patterns matter most\n","    2. Holiday effects are crucial (5x weight in WMAE)\n","    3. Seasonal patterns are strong\n","    4. Store characteristics affect sales magnitude\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.model = None\n","        self.feature_names = None\n","        self.label_encoders = {}\n","        self.feature_importance = None\n","\n","    def create_features(self, df, features_df, stores_df, is_training=True):\n","        \"\"\"\n","        Create features for XGBoost using learnings from ARIMA phase\n","        \"\"\"\n","        print(\"üîß Creating XGBoost features...\")\n","\n","        # Start with base data\n","        data = df.copy()\n","\n","        # Merge external data\n","        data = data.merge(features_df, on=['Store', 'Date'], how='left')\n","        data = data.merge(stores_df, on='Store', how='left')\n","\n","        # Convert dates\n","        data['Date'] = pd.to_datetime(data['Date'])\n","\n","        # üìÖ TIME FEATURES\n","        data['Year'] = data['Date'].dt.year\n","        data['Month'] = data['Date'].dt.month\n","        data['Week'] = data['Date'].dt.isocalendar().week\n","        data['DayOfYear'] = data['Date'].dt.dayofyear\n","        data['Quarter'] = data['Date'].dt.quarter\n","        data['WeekOfYear'] = data['Date'].dt.isocalendar().week\n","\n","        # üéÑ HOLIDAY FEATURES\n","        data['IsHoliday_x'] = data['IsHoliday_x'].astype(int)\n","\n","        # Holiday timing features\n","        data['Month_Dec'] = (data['Month'] == 12).astype(int)  # Christmas month\n","        data['Month_Nov'] = (data['Month'] == 11).astype(int)  # Thanksgiving\n","        data['Week_51_52'] = ((data['Week'] == 51) | (data['Week'] == 52)).astype(int)\n","\n","        # üè™ STORE & DEPARTMENT FEATURES\n","        # Keep as categorical - XGBoost handles these well\n","        data['Store'] = data['Store'].astype('category')\n","        data['Dept'] = data['Dept'].astype('category')\n","        data['Type'] = data['Type'].astype('category')\n","\n","        # Store size (numeric)\n","        data['Size'] = data['Size'].fillna(data['Size'].median())\n","\n","        # üå°Ô∏è EXTERNAL FEATURES (clean and enhance)\n","        # Handle missing values\n","        numeric_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n","        for col in numeric_cols:\n","            data[col] = data[col].fillna(data[col].median())\n","\n","        # üìä INTERACTION FEATURES (key for XGBoost performance)\n","        data['Holiday_x_Month'] = data['IsHoliday_x'] * data['Month']\n","        data['Holiday_x_Dept'] = data['IsHoliday_x'] * data['Dept'].cat.codes\n","        data['Store_x_Dept'] = data['Store'].cat.codes * data['Dept'].cat.codes\n","\n","        # üìà SEASONAL PATTERNS (from ARIMA insights)\n","        # Cyclical encoding for seasonality\n","        data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n","        data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n","        data['Week_sin'] = np.sin(2 * np.pi * data['Week'] / 52)\n","        data['Week_cos'] = np.cos(2 * np.pi * data['Week'] / 52)\n","\n","        print(f\"‚úÖ Feature engineering complete. Shape: {data.shape}\")\n","\n","        return data\n","\n","    def prepare_data(self, train_df, features_df, stores_df, test_df=None):\n","        \"\"\"\n","        Prepare training and test data for XGBoost\n","        \"\"\"\n","        print(\"üìä Preparing data for XGBoost...\")\n","\n","        # Create features for training data\n","        train_features = self.create_features(train_df, features_df, stores_df, is_training=True)\n","\n","        # Features to use (exclude target and identifiers)\n","        exclude_cols = ['Weekly_Sales', 'Date']\n","        if 'Id' in train_features.columns:\n","            exclude_cols.append('Id')\n","\n","        feature_cols = [col for col in train_features.columns if col not in exclude_cols]\n","\n","        # Handle categorical variables with label encoding\n","        categorical_cols = ['Store', 'Dept', 'Type']\n","\n","        for col in categorical_cols:\n","            if col in train_features.columns:\n","                le = LabelEncoder()\n","                train_features[col] = le.fit_transform(train_features[col].astype(str))\n","                self.label_encoders[col] = le\n","\n","        # Extract features and target\n","        X_train = train_features[feature_cols]\n","        y_train = train_features['Weekly_Sales']\n","\n","        self.feature_names = feature_cols\n","\n","        # Prepare test data if provided\n","        X_test = None\n","        if test_df is not None:\n","            test_features = self.create_features(test_df, features_df, stores_df, is_training=False)\n","\n","            # Apply same label encoding\n","            for col in categorical_cols:\n","                if col in test_features.columns and col in self.label_encoders:\n","                    # Handle unseen categories\n","                    test_features[col] = test_features[col].astype(str)\n","                    mask = test_features[col].isin(self.label_encoders[col].classes_)\n","                    test_features.loc[~mask, col] = self.label_encoders[col].classes_[0]  # Default to first class\n","                    test_features[col] = self.label_encoders[col].transform(test_features[col])\n","\n","            X_test = test_features[feature_cols]\n","\n","        print(f\"‚úÖ Data prepared - Train: {X_train.shape}, Target: {y_train.shape}\")\n","        if X_test is not None:\n","            print(f\"‚úÖ Test data prepared: {X_test.shape}\")\n","\n","        return X_train, y_train, X_test\n","\n","    def train(self, X_train, y_train, validation_split=0.2):\n","        \"\"\"\n","        Train XGBoost model with validation metrics\n","        \"\"\"\n","        print(\"üöÄ Training XGBoost model...\")\n","\n","        # Split for validation\n","        X_tr, X_val, y_tr, y_val = train_test_split(\n","            X_train, y_train, test_size=validation_split, random_state=42\n","        )\n","\n","        # Find holiday column for weighted metrics\n","        holiday_features = [col for col in X_train.columns if 'Holiday' in col or 'IsHoliday' in col]\n","\n","        if 'IsHoliday' in X_train.columns:\n","            holiday_col = 'IsHoliday'\n","        elif holiday_features:\n","            holiday_col = holiday_features[0]\n","        else:\n","            holiday_col = None\n","\n","        # Extract holiday flags\n","        if holiday_col:\n","            is_holiday_train = X_tr[holiday_col].values.astype(bool)\n","            is_holiday_val = X_val[holiday_col].values.astype(bool)\n","            print(f\"üìä Holiday weeks in train: {is_holiday_train.sum()}/{len(is_holiday_train)}\")\n","            print(f\"üìä Holiday weeks in val: {is_holiday_val.sum()}/{len(is_holiday_val)}\")\n","        else:\n","            print(\"‚ö†Ô∏è No holiday feature found\")\n","            is_holiday_train = np.zeros(len(X_tr), dtype=bool)\n","            is_holiday_val = np.zeros(len(X_val), dtype=bool)\n","\n","        # XGBoost parameters\n","        params = {\n","            'objective': 'reg:squarederror',\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'n_estimators': 500,\n","            'subsample': 0.8,\n","            'colsample_bytree': 0.8,\n","            'random_state': 42,\n","            'n_jobs': -1,\n","            'verbosity': 1\n","        }\n","\n","        # Train model\n","        self.model = xgb.XGBRegressor(**params)\n","        self.model.fit(X_tr, y_tr)\n","\n","        # Calculate metrics\n","        train_pred = self.model.predict(X_tr)\n","        val_pred = self.model.predict(X_val)\n","\n","        train_mae = mean_absolute_error(y_tr, train_pred)\n","        val_mae = mean_absolute_error(y_val, val_pred)\n","        train_wmae = calculate_wmae(y_tr, train_pred, is_holiday_train)\n","        val_wmae = calculate_wmae(y_val, val_pred, is_holiday_val)\n","\n","        # Feature importance\n","        self.feature_importance = pd.DataFrame({\n","            'feature': X_train.columns,\n","            'importance': self.model.feature_importances_\n","        }).sort_values('importance', ascending=False)\n","\n","        # Store metrics\n","        self.metrics = {\n","            'train_mae': train_mae,\n","            'val_mae': val_mae,\n","            'train_wmae': train_wmae,\n","            'val_wmae': val_wmae,\n","            'n_estimators': params['n_estimators']\n","        }\n","\n","        print(f\"‚úÖ Training complete!\")\n","        print(f\"   Training MAE: {train_mae:.2f}\")\n","        print(f\"   Validation MAE: {val_mae:.2f}\")\n","        print(f\"   Training WMAE: {train_wmae:.2f}\")\n","        print(f\"   Validation WMAE: {val_wmae:.2f}\")\n","\n","        return self.metrics\n","\n","    def predict(self, X_test):\n","        \"\"\"\n","        Generate predictions\n","        \"\"\"\n","        if self.model is None:\n","            raise ValueError(\"Model not trained yet!\")\n","\n","        predictions = self.model.predict(X_test)\n","\n","        # Ensure non-negative predictions\n","        predictions = np.maximum(0, predictions)\n","\n","        return predictions\n","\n","    def get_feature_importance(self, top_n=20):\n","        \"\"\"\n","        Get top feature importances\n","        \"\"\"\n","        if self.feature_importance is None:\n","            return None\n","\n","        return self.feature_importance.head(top_n)"],"metadata":{"id":"0FYxzMJXmTlF","executionInfo":{"status":"ok","timestamp":1751989109903,"user_tz":-240,"elapsed":35,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["#XGBoost Pipeline"],"metadata":{"id":"B6sBrdJgnL6L"}},{"cell_type":"code","source":["def complete_xgboost_pipeline(train_path, test_path, features_path, stores_path):\n","    \"\"\"\n","    Complete XGBoost pipeline for Walmart forecasting\n","    \"\"\"\n","    print(\"=\"*80)\n","    print(\"WALMART SALES FORECASTING - XGBOOST BASELINE\")\n","    print(\"=\"*80)\n","\n","    # Setup WandB\n","    wandb.init(\n","        project=\"walmart-forecasting\",\n","        name=f\"xgboost-baseline-{pd.Timestamp.now().strftime('%Y%m%d-%H%M%S')}\",\n","        tags=[\"xgboost\", \"baseline\"]\n","    )\n","\n","    try:\n","        # Load data\n","        print(\"üìÇ Loading data...\")\n","        train_df = pd.read_csv(train_path)\n","        test_df = pd.read_csv(test_path)\n","        features_df = pd.read_csv(features_path)\n","        stores_df = pd.read_csv(stores_path)\n","\n","        # Convert dates\n","        train_df['Date'] = pd.to_datetime(train_df['Date'])\n","        test_df['Date'] = pd.to_datetime(test_df['Date'])\n","        features_df['Date'] = pd.to_datetime(features_df['Date'])\n","\n","        # Create submission ID\n","        test_df['Id'] = (test_df['Store'].astype(str) + '_' +\n","                        test_df['Dept'].astype(str) + '_' +\n","                        test_df['Date'].dt.strftime('%Y-%m-%d'))\n","\n","        # Log data info\n","        wandb.config.update({\n","            'train_rows': len(train_df),\n","            'test_rows': len(test_df),\n","            'model_type': 'XGBoost',\n","            'approach': 'baseline'\n","        })\n","\n","        # Initialize and prepare\n","        model = WalmartXGBoostBaseline()\n","        X_train, y_train, X_test = model.prepare_data(train_df, features_df, stores_df, test_df)\n","\n","        # Train model\n","        metrics = model.train(X_train, y_train)\n","\n","        # Log metrics\n","        wandb.log({\n","            'train_mae': metrics['train_mae'],\n","            'val_mae': metrics['val_mae'],\n","            'train_wmae': metrics['train_wmae'],\n","            'val_wmae': metrics['val_wmae'],\n","            'train_samples': len(X_train),\n","            'features_count': len(model.feature_names)\n","        })\n","\n","        # Feature importance\n","        importance_df = model.get_feature_importance()\n","        if importance_df is not None:\n","            print(\"\\nüîç Top 10 Feature Importances:\")\n","            print(importance_df.head(10))\n","\n","            importance_table = wandb.Table(dataframe=importance_df.head(20))\n","            wandb.log({\"feature_importance\": importance_table})\n","\n","        # Generate predictions\n","        print(\"üîÆ Generating predictions...\")\n","        predictions = model.predict(X_test)\n","\n","        # Create submission\n","        submission_df = pd.DataFrame({\n","            'Id': test_df['Id'],\n","            'Weekly_Sales': predictions\n","        })\n","\n","        # Log submission stats\n","        wandb.log({\n","            'submission_total': len(submission_df),\n","            'submission_avg': predictions.mean(),\n","            'submission_std': predictions.std(),\n","            'submission_min': predictions.min(),\n","            'submission_max': predictions.max()\n","        })\n","\n","        # Save submission\n","        submission_filename = 'walmart_xgboost_submission.csv'\n","        submission_df.to_csv(submission_filename, index=False)\n","\n","        # Save model\n","        import joblib\n","        model_filename = 'xgboost_model.pkl'\n","        joblib.dump(model, model_filename)\n","\n","        # Create artifacts\n","        model_artifact = wandb.Artifact(\"xgboost_model\", type=\"model\")\n","        model_artifact.add_file(model_filename)\n","\n","        submission_artifact = wandb.Artifact(\"submission\", type=\"submission\")\n","        submission_artifact.add_file(submission_filename)\n","\n","        wandb.log_artifact(model_artifact)\n","        wandb.log_artifact(submission_artifact)\n","\n","        print(f\"\\n‚úÖ Pipeline Complete!\")\n","        print(f\"üìä Validation WMAE: {metrics['val_wmae']:.2f}\")\n","        print(f\"üìä Validation MAE: {metrics['val_mae']:.2f}\")\n","        print(f\"üìÅ Submission: {submission_filename}\")\n","        print(f\"üîó WandB: {wandb.run.url}\")\n","\n","        return model, submission_df, metrics\n","\n","    except Exception as e:\n","        print(f\"‚ùå Pipeline failed: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None\n","\n","    finally:\n","        wandb.finish()"],"metadata":{"id":"D8WJj1BmnNI8","executionInfo":{"status":"ok","timestamp":1751989165204,"user_tz":-240,"elapsed":48,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def run_xgboost_baseline():\n","    \"\"\"\n","    Run XGBoost baseline\n","    \"\"\"\n","    TRAIN_PATH = \"data/train.csv\"\n","    TEST_PATH = \"data/test.csv\"\n","    FEATURES_PATH = \"data/features.csv\"\n","    STORES_PATH = \"data/stores.csv\"\n","\n","    return complete_xgboost_pipeline(TRAIN_PATH, TEST_PATH, FEATURES_PATH, STORES_PATH)"],"metadata":{"id":"xYyCOCIJnrM5","executionInfo":{"status":"ok","timestamp":1751989223442,"user_tz":-240,"elapsed":45,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["result = run_xgboost_baseline()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tt2VCER3nthH","executionInfo":{"status":"ok","timestamp":1751989268285,"user_tz":-240,"elapsed":43201,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"5cad3459-97f5-4350-f4dd-71f5019f8e2b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","WALMART SALES FORECASTING - XGBOOST BASELINE\n","================================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.20.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/MLFinal/walmart-sales-forecasting/wandb/run-20250708_154024-0yjsea0d</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d' target=\"_blank\">xgboost-baseline-20250708-154024</a></strong> to <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üìÇ Loading data...\n","üìä Preparing data for XGBoost...\n","üîß Creating XGBoost features...\n","‚úÖ Feature engineering complete. Shape: (421570, 33)\n","üîß Creating XGBoost features...\n","‚úÖ Feature engineering complete. Shape: (115064, 33)\n","‚úÖ Data prepared - Train: (421570, 31), Target: (421570,)\n","‚úÖ Test data prepared: (115064, 31)\n","üöÄ Training XGBoost model...\n","üìä Holiday weeks in train: 23675/337256\n","üìä Holiday weeks in val: 5986/84314\n","‚úÖ Training complete!\n","   Training MAE: 2426.44\n","   Validation MAE: 2539.97\n","   Training WMAE: 2481.33\n","   Validation WMAE: 2636.78\n","\n","üîç Top 10 Feature Importances:\n","            feature  importance\n","1              Dept    0.229880\n","13             Type    0.138694\n","14             Size    0.138065\n","16            Month    0.054093\n","17             Week    0.045742\n","0             Store    0.043364\n","25   Holiday_x_Dept    0.043112\n","24  Holiday_x_Month    0.033984\n","26     Store_x_Dept    0.032191\n","20       WeekOfYear    0.026174\n","üîÆ Generating predictions...\n","\n","‚úÖ Pipeline Complete!\n","üìä Validation WMAE: 2636.78\n","üìä Validation MAE: 2539.97\n","üìÅ Submission: walmart_xgboost_submission.csv\n","üîó WandB: https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>features_count</td><td>‚ñÅ</td></tr><tr><td>submission_avg</td><td>‚ñÅ</td></tr><tr><td>submission_max</td><td>‚ñÅ</td></tr><tr><td>submission_min</td><td>‚ñÅ</td></tr><tr><td>submission_std</td><td>‚ñÅ</td></tr><tr><td>submission_total</td><td>‚ñÅ</td></tr><tr><td>train_mae</td><td>‚ñÅ</td></tr><tr><td>train_samples</td><td>‚ñÅ</td></tr><tr><td>train_wmae</td><td>‚ñÅ</td></tr><tr><td>val_mae</td><td>‚ñÅ</td></tr><tr><td>val_wmae</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>features_count</td><td>31</td></tr><tr><td>submission_avg</td><td>16626.85156</td></tr><tr><td>submission_max</td><td>557650</td></tr><tr><td>submission_min</td><td>0</td></tr><tr><td>submission_std</td><td>22371.36328</td></tr><tr><td>submission_total</td><td>115064</td></tr><tr><td>train_mae</td><td>2426.43801</td></tr><tr><td>train_samples</td><td>421570</td></tr><tr><td>train_wmae</td><td>2481.32775</td></tr><tr><td>val_mae</td><td>2539.96817</td></tr><tr><td>val_wmae</td><td>2636.78458</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">xgboost-baseline-20250708-154024</strong> at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting/runs/0yjsea0d</a><br> View project at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting</a><br>Synced 5 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250708_154024-0yjsea0d/logs</code>"]},"metadata":{}}]}]}