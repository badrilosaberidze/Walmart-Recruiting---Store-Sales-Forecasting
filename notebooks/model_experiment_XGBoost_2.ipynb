{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGqdqW41jIrRc16w1ZfR3Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Env Setup"],"metadata":{"id":"4GQRkim7wGTo"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCfw6HVVv3sY","executionInfo":{"status":"ok","timestamp":1751990145007,"user_tz":-240,"elapsed":19400,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"00f2decb-47a9-4e7c-863a-5775d43dab2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","with open('/content/drive/MyDrive/MLFinal/git_token.env', 'r') as f:\n","    token = f.read().strip()\n","\n","username = \"badrilosaberidze\"\n","\n","%cd /content/drive/MyDrive/MLFinal/walmart-sales-forecasting\n","!git remote set-url origin https://{username}:{token}@github.com/{username}/Walmart-Recruiting---Store-Sales-Forecasting.git\n","!git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxN057LLwA8v","executionInfo":{"status":"ok","timestamp":1751990156693,"user_tz":-240,"elapsed":9411,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"6b36b7ce-f6e2-4ee0-ced8-d8674e8589bc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MLFinal/walmart-sales-forecasting\n","Already up to date.\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.preprocessing import LabelEncoder, TargetEncoder\n","from sklearn.metrics import mean_absolute_error\n","import wandb"],"metadata":{"id":"v2xPTXHkwFrV","executionInfo":{"status":"ok","timestamp":1751990177533,"user_tz":-240,"elapsed":4454,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Custom WMae functions"],"metadata":{"id":"EtoxVbXvwROG"}},{"cell_type":"code","source":["def wmae_objective(y_pred, y_true, is_holiday):\n","    \"\"\"\n","    Custom WMAE objective function for XGBoost\n","    \"\"\"\n","    # Get holiday weights\n","    weights = np.where(is_holiday, 5.0, 1.0)\n","\n","    # Calculate weighted residuals\n","    residuals = y_true.get_label() - y_pred\n","    weighted_residuals = weights * residuals\n","\n","    # Gradient: derivative of WMAE w.r.t. predictions\n","    grad = -np.sign(weighted_residuals) * weights / np.sum(weights)\n","\n","    # Hessian: second derivative (approximate for MAE)\n","    hess = np.ones_like(grad) * 0.1  # Small constant for numerical stability\n","\n","    return grad, hess\n"],"metadata":{"id":"3v49PmJfwTeO","executionInfo":{"status":"ok","timestamp":1751990225800,"user_tz":-240,"elapsed":5,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def wmae_eval(y_pred, y_true, is_holiday):\n","    \"\"\"\n","    Custom WMAE evaluation function for XGBoost\n","    \"\"\"\n","    weights = np.where(is_holiday, 5.0, 1.0)\n","    weighted_errors = weights * np.abs(y_true.get_label() - y_pred)\n","    wmae = np.sum(weighted_errors) / np.sum(weights)\n","    return 'wmae', wmae"],"metadata":{"id":"4kJj3qi5wVDo","executionInfo":{"status":"ok","timestamp":1751990228502,"user_tz":-240,"elapsed":6,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def calculate_wmae(y_true, y_pred, is_holiday):\n","    \"\"\"\n","    Calculate Weighted Mean Absolute Error (WMAE)\n","    Holiday weeks have 5x weight\n","    \"\"\"\n","    weights = np.where(is_holiday, 5.0, 1.0)\n","    weighted_errors = weights * np.abs(y_true - y_pred)\n","    wmae = np.sum(weighted_errors) / np.sum(weights)\n","    return wmae"],"metadata":{"id":"18_dtXvMw01J","executionInfo":{"status":"ok","timestamp":1751990361607,"user_tz":-240,"elapsed":9,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Advanced XGBoost model"],"metadata":{"id":"dycrWsllwerh"}},{"cell_type":"code","source":["class AdvancedWalmartXGBoost:\n","    \"\"\"\n","    Advanced XGBoost with time series features and custom WMAE objective\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.model = None\n","        self.feature_names = None\n","        self.target_encoders = {}\n","        self.feature_importance = None\n","        self.metrics = None\n","\n","    def create_advanced_features(self, df, features_df, stores_df, is_training=True):\n","        \"\"\"\n","        Create advanced features\n","        \"\"\"\n","        print(\"üîß Creating features (same for train/test)...\")\n","\n","        data = df.copy()\n","        data = data.merge(features_df, on=['Store', 'Date'], how='left')\n","        data = data.merge(stores_df, on='Store', how='left')\n","        data['Date'] = pd.to_datetime(data['Date'])\n","\n","        # TIME FEATURES (same for both)\n","        data['Year'] = data['Date'].dt.year\n","        data['Month'] = data['Date'].dt.month\n","        data['Week'] = data['Date'].dt.isocalendar().week\n","        data['Quarter'] = data['Date'].dt.quarter\n","        data['WeekOfMonth'] = data['Date'].dt.day // 7 + 1\n","\n","        # HOLIDAY FEATURES (same for both)\n","        holiday_col = 'IsHoliday_x' if 'IsHoliday_x' in data.columns else 'IsHoliday'\n","        if holiday_col in data.columns:\n","            data['IsHoliday'] = data[holiday_col].astype(int)\n","        else:\n","            data['IsHoliday'] = 0\n","\n","        data['Holiday_Month'] = data['IsHoliday'] * data['Month']\n","        data['Christmas_Season'] = ((data['Month'] == 12) & (data['Week'] >= 50)).astype(int)\n","        data['Thanksgiving_Week'] = ((data['Month'] == 11) & (data['Week'] >= 46)).astype(int)\n","\n","        # CATEGORICAL ENCODING (same for both)\n","        data['Store'] = data['Store'].astype('category').cat.codes\n","        data['Dept'] = data['Dept'].astype('category').cat.codes\n","        data['Type'] = data['Type'].astype('category').cat.codes\n","\n","        # EXTERNAL FEATURES (same for both)\n","        numeric_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size']\n","        for col in numeric_cols:\n","            if col in data.columns:\n","                data[col] = data[col].fillna(data[col].median())\n","                data[f'{col}_x_Holiday'] = data[col] * data['IsHoliday']\n","\n","        # INTERACTIONS (same for both)\n","        data['Store_x_Dept'] = data['Store'] * data['Dept']\n","        data['Month_x_Dept'] = data['Month'] * data['Dept']\n","        data['Holiday_x_Size'] = data['IsHoliday'] * data['Size']\n","        data['Christmas_x_Dept'] = data['Christmas_Season'] * data['Dept']\n","\n","        # SEASONAL ENCODING (same for both)\n","        data['Month_sin'] = np.sin(2 * np.pi * data['Month'] / 12)\n","        data['Month_cos'] = np.cos(2 * np.pi * data['Month'] / 12)\n","        data['Week_sin'] = np.sin(2 * np.pi * data['Week'] / 52)\n","        data['Week_cos'] = np.cos(2 * np.pi * data['Week'] / 52)\n","\n","        data = data.fillna(0)\n","\n","        print(f\"‚úÖ Feature engineering complete. Shape: {data.shape}\")\n","        print(f\"üìä Features are identical for train/test: {not is_training}\")\n","\n","        return data\n","\n","    def prepare_data(self, train_df, features_df, stores_df, test_df=None):\n","        \"\"\"\n","        Prepare data with advanced features\n","        \"\"\"\n","        print(\"üìä Preparing data with proper target encoding...\")\n","\n","        # Create features for training (without target encoding)\n","        train_features = self.create_advanced_features(train_df, features_df, stores_df, is_training=True)\n","\n","        # TIME-AWARE SPLIT FIRST (before target encoding)\n","        split_idx = int(len(train_features) * 0.8)\n","        train_part = train_features.iloc[:split_idx].copy()\n","        val_part = train_features.iloc[split_idx:].copy()\n","\n","        print(f\"üìä Split: Train {len(train_part)}, Validation {len(val_part)}\")\n","\n","        # TARGET ENCODING: Use only train part to calculate encodings\n","        if 'Weekly_Sales' in train_part.columns:\n","            print(\"üìä Calculating target encodings from train part only...\")\n","\n","            # Calculate encodings from train part only\n","            store_means = train_part.groupby('Store')['Weekly_Sales'].mean()\n","            dept_means = train_part.groupby('Dept')['Weekly_Sales'].mean()\n","\n","            # Apply to train part\n","            train_part['Store_TargetEnc'] = train_part['Store'].map(store_means)\n","            train_part['Dept_TargetEnc'] = train_part['Dept'].map(dept_means)\n","\n","            # Apply to validation part (no leakage)\n","            val_part['Store_TargetEnc'] = val_part['Store'].map(store_means).fillna(store_means.mean())\n","            val_part['Dept_TargetEnc'] = val_part['Dept'].map(dept_means).fillna(dept_means.mean())\n","\n","            # Store encoders for test data\n","            self.target_encoders = {'Store': store_means, 'Dept': dept_means}\n","\n","            # Combine back\n","            train_features_fixed = pd.concat([train_part, val_part], ignore_index=True)\n","        else:\n","            train_features_fixed = train_features\n","            train_features_fixed['Store_TargetEnc'] = 0\n","            train_features_fixed['Dept_TargetEnc'] = 0\n","\n","        # Feature columns\n","        exclude_cols = ['Weekly_Sales', 'Date', 'Id']\n","        feature_cols = [col for col in train_features_fixed.columns if col not in exclude_cols]\n","\n","        X_train = train_features_fixed[feature_cols]\n","        y_train = train_features_fixed['Weekly_Sales']\n","\n","        self.feature_names = feature_cols\n","\n","        # Prepare test data\n","        X_test = None\n","        if test_df is not None:\n","            test_features = self.create_advanced_features(test_df, features_df, stores_df, is_training=False)\n","\n","            # Apply stored target encodings to test\n","            if hasattr(self, 'target_encoders'):\n","                test_features['Store_TargetEnc'] = test_features['Store'].map(self.target_encoders['Store']).fillna(self.target_encoders['Store'].mean())\n","                test_features['Dept_TargetEnc'] = test_features['Dept'].map(self.target_encoders['Dept']).fillna(self.target_encoders['Dept'].mean())\n","            else:\n","                test_features['Store_TargetEnc'] = 0\n","                test_features['Dept_TargetEnc'] = 0\n","\n","            X_test = test_features[feature_cols]\n","\n","        print(f\"‚úÖ Data prepared - Train: {X_train.shape}, Target: {y_train.shape}\")\n","        if X_test is not None:\n","            print(f\"‚úÖ Test data: {X_test.shape}\")\n","\n","        return X_train, y_train, X_test\n","\n","    def train(self, X_train, y_train, validation_split=0.2):\n","        print(\"üöÄ Training XGBoost with standard objective...\")\n","\n","        # Time series split\n","        split_idx = int(len(X_train) * (1 - validation_split))\n","\n","        X_tr = X_train.iloc[:split_idx]\n","        X_val = X_train.iloc[split_idx:]\n","        y_tr = y_train.iloc[:split_idx]\n","        y_val = y_train.iloc[split_idx:]\n","\n","        # Get holiday flags for evaluation only\n","        is_holiday_train = X_tr['IsHoliday'].values.astype(bool)\n","        is_holiday_val = X_val['IsHoliday'].values.astype(bool)\n","\n","        print(f\"üìä Holiday weeks - Train: {is_holiday_train.sum()}/{len(is_holiday_train)}, Val: {is_holiday_val.sum()}/{len(is_holiday_val)}\")\n","\n","        # FIXED: Use standard XGBoost objective (not custom)\n","        params = {\n","            'objective': 'reg:squarederror',  # Standard objective\n","            'eval_metric': 'mae',\n","            'max_depth': 7,\n","            'learning_rate': 0.05,\n","            'n_estimators': 800,\n","            'subsample': 0.8,\n","            'colsample_bytree': 0.8,\n","            'random_state': 42,\n","            'n_jobs': -1,\n","            'verbosity': 1\n","        }\n","\n","        # FIXED: Standard XGBRegressor training\n","        self.model = xgb.XGBRegressor(**params)\n","        self.model.fit(X_tr, y_tr)\n","\n","        # Calculate metrics\n","        train_pred = self.model.predict(X_tr)\n","        val_pred = self.model.predict(X_val)\n","\n","        train_mae = mean_absolute_error(y_tr, train_pred)\n","        val_mae = mean_absolute_error(y_val, val_pred)\n","        train_wmae = calculate_wmae(y_tr, train_pred, is_holiday_train)\n","        val_wmae = calculate_wmae(y_val, val_pred, is_holiday_val)\n","\n","        # Feature importance\n","        self.feature_importance = pd.DataFrame({\n","            'feature': X_train.columns,\n","            'importance': self.model.feature_importances_\n","        }).sort_values('importance', ascending=False)\n","\n","        self.metrics = {\n","            'train_mae': train_mae,\n","            'val_mae': val_mae,\n","            'train_wmae': train_wmae,\n","            'val_wmae': val_wmae,\n","            'n_estimators': params['n_estimators']\n","        }\n","\n","        print(f\"‚úÖ Training complete!\")\n","        print(f\"   Training MAE: {train_mae:.2f}\")\n","        print(f\"   Validation MAE: {val_mae:.2f}\")\n","        print(f\"   Training WMAE: {train_wmae:.2f}\")\n","        print(f\"   Validation WMAE: {val_wmae:.2f}\")\n","\n","        return self.metrics\n","\n","    def predict(self, X_test):\n","        if self.model is None:\n","            raise ValueError(\"Model not trained yet!\")\n","\n","        # FIXED: Standard sklearn prediction\n","        predictions = self.model.predict(X_test)\n","        predictions = np.maximum(0, predictions)  # Ensure non-negative\n","\n","        return predictions\n","\n","    def get_feature_importance(self, top_n=20):\n","        \"\"\"\n","        Get feature importance\n","        \"\"\"\n","        if self.feature_importance is None:\n","            return None\n","        return self.feature_importance.head(top_n)"],"metadata":{"id":"OWfKiIdiwge_","executionInfo":{"status":"ok","timestamp":1751993730277,"user_tz":-240,"elapsed":23,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["#Complete Pipeline"],"metadata":{"id":"1j33a6WSw5s3"}},{"cell_type":"code","source":["def complete_advanced_xgboost_pipeline(train_path, test_path, features_path, stores_path):\n","    \"\"\"\n","    Complete advanced XGBoost pipeline with custom WMAE objective\n","    \"\"\"\n","    print(\"=\"*80)\n","    print(\"WALMART SALES FORECASTING - ADVANCED XGBOOST\")\n","    print(\"=\"*80)\n","\n","    wandb.init(\n","        project=\"walmart-forecasting_XGBoost\",\n","        name=f\"xgboost-advanced-{pd.Timestamp.now().strftime('%Y%m%d-%H%M%S')}\",\n","        tags=[\"xgboost\", \"advanced\", \"custom-wmae\", \"time-series-features\"]\n","    )\n","\n","    try:\n","        # Load data\n","        print(\"üìÇ Loading data...\")\n","        train_df = pd.read_csv(train_path)\n","        test_df = pd.read_csv(test_path)\n","        features_df = pd.read_csv(features_path)\n","        stores_df = pd.read_csv(stores_path)\n","\n","        # Convert dates\n","        train_df['Date'] = pd.to_datetime(train_df['Date'])\n","        test_df['Date'] = pd.to_datetime(test_df['Date'])\n","        features_df['Date'] = pd.to_datetime(features_df['Date'])\n","\n","        # Create submission ID\n","        test_df['Id'] = (test_df['Store'].astype(str) + '_' +\n","                        test_df['Dept'].astype(str) + '_' +\n","                        test_df['Date'].dt.strftime('%Y-%m-%d'))\n","\n","        # Log config\n","        wandb.config.update({\n","            'model_type': 'XGBoost Advanced',\n","            'custom_objective': 'WMAE',\n","            'time_series_features': True,\n","            'target_encoding': True,\n","            'train_rows': len(train_df)\n","        })\n","\n","        # Initialize and train\n","        model = AdvancedWalmartXGBoost()\n","        X_train, y_train, X_test = model.prepare_data(train_df, features_df, stores_df, test_df)\n","\n","        # Train with custom WMAE\n","        metrics = model.train(X_train, y_train)\n","\n","        # Log metrics\n","        wandb.log({\n","            'train_mae': metrics['train_mae'],\n","            'val_mae': metrics['val_mae'],\n","            'train_wmae': metrics['train_wmae'],\n","            'val_wmae': metrics['val_wmae'],\n","            'n_estimators': metrics['n_estimators'],\n","            'features_count': len(model.feature_names)\n","        })\n","\n","        # Feature importance\n","        importance_df = model.get_feature_importance()\n","        print(\"\\nüîç Top 15 Feature Importances:\")\n","        print(importance_df.head(15))\n","\n","        # Generate predictions\n","        predictions = model.predict(X_test)\n","\n","        # Create submission\n","        submission_df = pd.DataFrame({\n","            'Id': test_df['Id'],\n","            'Weekly_Sales': predictions\n","        })\n","\n","        # Save results\n","        submission_filename = 'walmart_xgboost_advanced_submission.csv'\n","        submission_df.to_csv(submission_filename, index=False)\n","\n","        print(f\"\\n‚úÖ Advanced XGBoost Complete!\")\n","        print(f\"üìä Validation WMAE: {metrics['val_wmae']:.2f}\")\n","        print(f\"üìÅ Submission: {submission_filename}\")\n","\n","        return model, submission_df, metrics\n","\n","    except Exception as e:\n","        print(f\"‚ùå Pipeline failed: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None\n","\n","    finally:\n","        wandb.finish()"],"metadata":{"id":"dNBM2Tuuw7Cg","executionInfo":{"status":"ok","timestamp":1751993895589,"user_tz":-240,"elapsed":52,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["TRAIN_PATH = \"data/train.csv\"\n","TEST_PATH = \"data/test.csv\"\n","FEATURES_PATH = \"data/features.csv\"\n","STORES_PATH = \"data/stores.csv\"\n","\n","result = complete_advanced_xgboost_pipeline(TRAIN_PATH, TEST_PATH, FEATURES_PATH, STORES_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"j5EMi0K7xJfX","executionInfo":{"status":"ok","timestamp":1751993794185,"user_tz":-240,"elapsed":60126,"user":{"displayName":"Badri Losaberidze","userId":"06913732304764740270"}},"outputId":"31462dda-2520-4937-8130-d82b5b632131"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","WALMART SALES FORECASTING - ADVANCED XGBOOST\n","================================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.20.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/MLFinal/walmart-sales-forecasting/wandb/run-20250708_165533-znud3ehm</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost/runs/znud3ehm' target=\"_blank\">xgboost-advanced-20250708-165533</a></strong> to <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost/runs/znud3ehm' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost/runs/znud3ehm</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üìÇ Loading data...\n","üìä Preparing data with proper target encoding...\n","üîß Creating features (same for train/test)...\n","‚úÖ Feature engineering complete. Shape: (421570, 39)\n","üìä Features are identical for train/test: False\n","üìä Split: Train 337256, Validation 84314\n","üìä Calculating target encodings from train part only...\n","üîß Creating features (same for train/test)...\n","‚úÖ Feature engineering complete. Shape: (115064, 39)\n","üìä Features are identical for train/test: True\n","‚úÖ Data prepared - Train: (421570, 39), Target: (421570,)\n","‚úÖ Test data: (115064, 39)\n","üöÄ Training XGBoost with standard objective...\n","üìä Holiday weeks - Train: 23740/337256, Val: 5921/84314\n","‚úÖ Training complete!\n","   Training MAE: 1718.00\n","   Validation MAE: 8386.46\n","   Training WMAE: 1747.35\n","   Validation WMAE: 8594.48\n","\n","üîç Top 15 Feature Importances:\n","              feature  importance\n","38     Dept_TargetEnc    0.184926\n","37    Store_TargetEnc    0.167549\n","1                Dept    0.087168\n","14               Size    0.082060\n","16              Month    0.049637\n","13               Type    0.044855\n","22   Christmas_Season    0.041931\n","21      Holiday_Month    0.041897\n","17               Week    0.026208\n","12        IsHoliday_y    0.025452\n","32   Christmas_x_Dept    0.024281\n","33          Month_sin    0.020210\n","30       Month_x_Dept    0.019832\n","23  Thanksgiving_Week    0.019115\n","0               Store    0.018758\n","\n","‚úÖ Advanced XGBoost Complete!\n","üìä Validation WMAE: 8594.48\n","üéØ Target: Beat ARIMA's ~4,400 WMAE\n","üìÅ Submission: walmart_xgboost_advanced_submission.csv\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>features_count</td><td>‚ñÅ</td></tr><tr><td>n_estimators</td><td>‚ñÅ</td></tr><tr><td>train_mae</td><td>‚ñÅ</td></tr><tr><td>train_wmae</td><td>‚ñÅ</td></tr><tr><td>val_mae</td><td>‚ñÅ</td></tr><tr><td>val_wmae</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>features_count</td><td>39</td></tr><tr><td>n_estimators</td><td>800</td></tr><tr><td>train_mae</td><td>1718.00391</td></tr><tr><td>train_wmae</td><td>1747.35188</td></tr><tr><td>val_mae</td><td>8386.4559</td></tr><tr><td>val_wmae</td><td>8594.48372</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">xgboost-advanced-20250708-165533</strong> at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost/runs/znud3ehm' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost/runs/znud3ehm</a><br> View project at: <a href='https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost' target=\"_blank\">https://wandb.ai/blosa22-free-university-of-tbilisi-/walmart-forecasting_XGBoost</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250708_165533-znud3ehm/logs</code>"]},"metadata":{}}]}]}